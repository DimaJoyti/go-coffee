apiVersion: argoproj.io/v1alpha1
kind: Rollout
metadata:
  name: go-coffee-api-gateway
  namespace: go-coffee
  labels:
    app: go-coffee-api-gateway
    deployment-strategy: blue-green-canary
spec:
  replicas: 10
  strategy:
    canary:
      # Canary deployment configuration
      canaryService: go-coffee-api-gateway-canary
      stableService: go-coffee-api-gateway-stable
      trafficRouting:
        nginx:
          stableIngress: go-coffee-api-gateway-stable
          annotationPrefix: nginx.ingress.kubernetes.io
          additionalIngressAnnotations:
            canary-by-header: X-Canary
            canary-by-header-value: "true"
      steps:
      # Step 1: Deploy canary with 5% traffic
      - setWeight: 5
      - pause:
          duration: 2m
      
      # Step 2: Increase to 10% and run analysis
      - setWeight: 10
      - pause:
          duration: 5m
      - analysis:
          templates:
          - templateName: success-rate
          - templateName: latency-check
          args:
          - name: service-name
            value: go-coffee-api-gateway-canary
      
      # Step 3: Increase to 25% with extended analysis
      - setWeight: 25
      - pause:
          duration: 10m
      - analysis:
          templates:
          - templateName: comprehensive-analysis
          args:
          - name: service-name
            value: go-coffee-api-gateway-canary
          - name: baseline-service
            value: go-coffee-api-gateway-stable
      
      # Step 4: Increase to 50% with business metrics validation
      - setWeight: 50
      - pause:
          duration: 15m
      - analysis:
          templates:
          - templateName: business-metrics-analysis
          args:
          - name: service-name
            value: go-coffee-api-gateway-canary
      
      # Step 5: Full rollout
      - setWeight: 100
      - pause:
          duration: 5m
      
      # Analysis templates for automated decision making
      analysisRunMetadata:
        labels:
          deployment: canary
        annotations:
          deployment.strategy: "canary"
      
      # Automatic rollback conditions
      abortScaleDownDelaySeconds: 30
      scaleDownDelaySeconds: 30
      
  selector:
    matchLabels:
      app: go-coffee-api-gateway
  template:
    metadata:
      labels:
        app: go-coffee-api-gateway
    spec:
      containers:
      - name: api-gateway
        image: go-coffee/api-gateway:latest
        ports:
        - containerPort: 8080
          name: http
        - containerPort: 9090
          name: metrics
        env:
        - name: DEPLOYMENT_STRATEGY
          value: "canary"
        - name: CANARY_ENABLED
          value: "true"
        resources:
          requests:
            cpu: 200m
            memory: 256Mi
          limits:
            cpu: 1000m
            memory: 1Gi
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: success-rate
  namespace: go-coffee
  labels:
    app: go-coffee
    component: analysis
spec:
  args:
  - name: service-name
  metrics:
  - name: success-rate
    interval: 1m
    count: 5
    successCondition: result[0] >= 0.95
    failureLimit: 3
    provider:
      prometheus:
        address: http://prometheus.monitoring.svc.cluster.local:9090
        query: |
          sum(rate(http_requests_total{service="{{args.service-name}}",status!~"5.."}[2m])) /
          sum(rate(http_requests_total{service="{{args.service-name}}"}[2m]))

---
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: latency-check
  namespace: go-coffee
  labels:
    app: go-coffee
    component: analysis
spec:
  args:
  - name: service-name
  metrics:
  - name: p95-latency
    interval: 1m
    count: 5
    successCondition: result[0] <= 0.5
    failureLimit: 3
    provider:
      prometheus:
        address: http://prometheus.monitoring.svc.cluster.local:9090
        query: |
          histogram_quantile(0.95,
            sum(rate(http_request_duration_seconds_bucket{service="{{args.service-name}}"}[2m])) by (le)
          )
  - name: p99-latency
    interval: 1m
    count: 5
    successCondition: result[0] <= 1.0
    failureLimit: 2
    provider:
      prometheus:
        address: http://prometheus.monitoring.svc.cluster.local:9090
        query: |
          histogram_quantile(0.99,
            sum(rate(http_request_duration_seconds_bucket{service="{{args.service-name}}"}[2m])) by (le)
          )

---
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: comprehensive-analysis
  namespace: go-coffee
  labels:
    app: go-coffee
    component: analysis
spec:
  args:
  - name: service-name
  - name: baseline-service
  metrics:
  # Error rate comparison
  - name: error-rate-comparison
    interval: 2m
    count: 5
    successCondition: result[0] <= 1.1  # Max 10% increase in error rate
    failureLimit: 3
    provider:
      prometheus:
        address: http://prometheus.monitoring.svc.cluster.local:9090
        query: |
          (
            sum(rate(http_requests_total{service="{{args.service-name}}",status=~"5.."}[5m])) /
            sum(rate(http_requests_total{service="{{args.service-name}}"}[5m]))
          ) / (
            sum(rate(http_requests_total{service="{{args.baseline-service}}",status=~"5.."}[5m])) /
            sum(rate(http_requests_total{service="{{args.baseline-service}}"}[5m]))
          )
  
  # Latency comparison
  - name: latency-comparison
    interval: 2m
    count: 5
    successCondition: result[0] <= 1.2  # Max 20% increase in latency
    failureLimit: 3
    provider:
      prometheus:
        address: http://prometheus.monitoring.svc.cluster.local:9090
        query: |
          (
            histogram_quantile(0.95,
              sum(rate(http_request_duration_seconds_bucket{service="{{args.service-name}}"}[5m])) by (le)
            )
          ) / (
            histogram_quantile(0.95,
              sum(rate(http_request_duration_seconds_bucket{service="{{args.baseline-service}}"}[5m])) by (le)
            )
          )
  
  # Memory usage check
  - name: memory-usage
    interval: 1m
    count: 5
    successCondition: result[0] <= 0.8  # Max 80% memory usage
    failureLimit: 3
    provider:
      prometheus:
        address: http://prometheus.monitoring.svc.cluster.local:9090
        query: |
          avg(container_memory_working_set_bytes{pod=~"{{args.service-name}}-.*"}) /
          avg(container_spec_memory_limit_bytes{pod=~"{{args.service-name}}-.*"})
  
  # CPU usage check
  - name: cpu-usage
    interval: 1m
    count: 5
    successCondition: result[0] <= 0.7  # Max 70% CPU usage
    failureLimit: 3
    provider:
      prometheus:
        address: http://prometheus.monitoring.svc.cluster.local:9090
        query: |
          avg(rate(container_cpu_usage_seconds_total{pod=~"{{args.service-name}}-.*"}[2m])) /
          avg(container_spec_cpu_quota{pod=~"{{args.service-name}}-.*"} / container_spec_cpu_period{pod=~"{{args.service-name}}-.*"})

---
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: business-metrics-analysis
  namespace: go-coffee
  labels:
    app: go-coffee
    component: analysis
spec:
  args:
  - name: service-name
  metrics:
  # Order success rate
  - name: order-success-rate
    interval: 2m
    count: 5
    successCondition: result[0] >= 0.98  # Min 98% order success rate
    failureLimit: 2
    provider:
      prometheus:
        address: http://prometheus.monitoring.svc.cluster.local:9090
        query: |
          sum(rate(coffee_orders_total{status="completed",service="{{args.service-name}}"}[5m])) /
          sum(rate(coffee_orders_total{service="{{args.service-name}}"}[5m]))
  
  # Payment success rate
  - name: payment-success-rate
    interval: 2m
    count: 5
    successCondition: result[0] >= 0.99  # Min 99% payment success rate
    failureLimit: 1
    provider:
      prometheus:
        address: http://prometheus.monitoring.svc.cluster.local:9090
        query: |
          sum(rate(coffee_payments_total{status="success",service="{{args.service-name}}"}[5m])) /
          sum(rate(coffee_payments_total{service="{{args.service-name}}"}[5m]))
  
  # Cache hit rate
  - name: cache-hit-rate
    interval: 1m
    count: 5
    successCondition: result[0] >= 0.8  # Min 80% cache hit rate
    failureLimit: 3
    provider:
      prometheus:
        address: http://prometheus.monitoring.svc.cluster.local:9090
        query: |
          sum(rate(cache_requests_total{status="hit",service="{{args.service-name}}"}[2m])) /
          sum(rate(cache_requests_total{service="{{args.service-name}}"}[2m]))

---
apiVersion: v1
kind: Service
metadata:
  name: go-coffee-api-gateway-stable
  namespace: go-coffee
  labels:
    app: go-coffee-api-gateway
    version: stable
spec:
  selector:
    app: go-coffee-api-gateway
  ports:
  - name: http
    port: 80
    targetPort: 8080
  - name: metrics
    port: 9090
    targetPort: 9090

---
apiVersion: v1
kind: Service
metadata:
  name: go-coffee-api-gateway-canary
  namespace: go-coffee
  labels:
    app: go-coffee-api-gateway
    version: canary
spec:
  selector:
    app: go-coffee-api-gateway
  ports:
  - name: http
    port: 80
    targetPort: 8080
  - name: metrics
    port: 9090
    targetPort: 9090

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: go-coffee-api-gateway-stable
  namespace: go-coffee
  labels:
    app: go-coffee-api-gateway
    version: stable
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/use-regex: "true"
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - api.go-coffee.com
    secretName: go-coffee-tls
  rules:
  - host: api.go-coffee.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: go-coffee-api-gateway-stable
            port:
              number: 80

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: go-coffee-api-gateway-canary
  namespace: go-coffee
  labels:
    app: go-coffee-api-gateway
    version: canary
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/use-regex: "true"
    nginx.ingress.kubernetes.io/canary: "true"
    nginx.ingress.kubernetes.io/canary-weight: "0"
    nginx.ingress.kubernetes.io/canary-by-header: "X-Canary"
    nginx.ingress.kubernetes.io/canary-by-header-value: "true"
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - api.go-coffee.com
    secretName: go-coffee-tls
  rules:
  - host: api.go-coffee.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: go-coffee-api-gateway-canary
            port:
              number: 80

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: deployment-strategy-config
  namespace: go-coffee
  labels:
    app: go-coffee
    component: deployment
data:
  strategy.yaml: |
    # Deployment Strategy Configuration
    strategies:
      # Blue-Green Deployment
      blue_green:
        enabled: true
        auto_promotion: false
        scale_down_delay: "30s"
        pre_promotion_analysis:
          - success-rate
          - latency-check
        post_promotion_analysis:
          - comprehensive-analysis
        rollback_window: "10m"
        
      # Canary Deployment
      canary:
        enabled: true
        max_surge: "25%"
        max_unavailable: "25%"
        steps:
          - weight: 5
            pause: "2m"
          - weight: 10
            pause: "5m"
            analysis: ["success-rate", "latency-check"]
          - weight: 25
            pause: "10m"
            analysis: ["comprehensive-analysis"]
          - weight: 50
            pause: "15m"
            analysis: ["business-metrics-analysis"]
          - weight: 100
            pause: "5m"
        
        # Automatic rollback conditions
        abort_conditions:
          - error_rate_threshold: 0.05  # 5% error rate
          - latency_threshold: "1s"     # 1 second P95 latency
          - success_rate_threshold: 0.95 # 95% success rate
        
        # Traffic splitting
        traffic_routing:
          method: "header"  # header, weight, or cookie
          header_name: "X-Canary"
          header_value: "true"
          
      # Feature Flags Integration
      feature_flags:
        enabled: true
        provider: "launchdarkly"  # or "flagsmith", "split"
        flags:
          - name: "new-payment-flow"
            rollout_percentage: 10
            targeting_rules:
              - attribute: "user_tier"
                operator: "in"
                values: ["premium", "enterprise"]
          - name: "enhanced-analytics"
            rollout_percentage: 25
            targeting_rules:
              - attribute: "region"
                operator: "in"
                values: ["us-west", "eu-central"]
    
    # Monitoring and Alerting
    monitoring:
      sli_slo:
        availability:
          target: 99.9
          measurement_window: "30d"
        latency:
          p95_target: "200ms"
          p99_target: "500ms"
        error_rate:
          target: "0.1%"
          measurement_window: "5m"
      
      alerts:
        deployment_failure:
          condition: "rollout_== 'Degraded'"
          severity: "critical"
          notification_channels: ["slack", "pagerduty"]
        
        high_error_rate:
          condition: "error_rate > 0.05"
          duration: "2m"
          severity: "warning"
          notification_channels: ["slack"]
        
        rollback_triggered:
          condition: "rollout_status == 'Aborted'"
          severity: "warning"
          notification_channels: ["slack", "email"]

---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: deployment-health-check
  namespace: go-coffee
  labels:
    app: go-coffee
    component: deployment-monitoring
spec:
  schedule: "*/5 * * * *"  # Every 5 minutes
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: health-checker
            image: go-coffee/deployment-monitor:latest
            command:
            - /bin/sh
            - -c
            - |
              echo "Checking deployment health..."
              
              # Check rollout status
              ROLLOUT_STATUS=$(kubectl get rollout go-coffee-api-gateway -n go-coffee -o jsonpath='{.status.phase}')
              echo "Rollout status: $ROLLOUT_STATUS"
              
              # Check if any analysis runs are failing
              FAILED_ANALYSIS=$(kubectl get analysisrun -n go-coffee --field-selector=status.phase=Failed --no-headers | wc -l)
              if [ "$FAILED_ANALYSIS" -gt 0 ]; then
                echo "WARNING: $FAILED_ANALYSIS failed analysis runs detected"
              fi
              
              # Check service health
              kubectl get pods -n go-coffee -l app=go-coffee-api-gateway --no-headers | \
                awk '{print $1, $3}' | while read pod status; do
                if [ "$status" != "Running" ]; then
                  echo "WARNING: Pod $pod is in $status state"
                fi
              done
              
              echo "Deployment health check completed"
            resources:
              requests:
                cpu: 50m
                memory: 64Mi
              limits:
                cpu: 100m
                memory: 128Mi
          restartPolicy: OnFailure
