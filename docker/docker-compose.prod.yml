# Docker Compose for Production
# Use with: docker-compose -f docker-compose.yml -f docker-compose.prod.yml up

version: '3.8'

services:
  # Production auth service
  auth-service:
    build:
      target: production
    environment:
      - ENVIRONMENT=production
      - LOG_LEVEL=info
      - LOG_FORMAT=json
      - ENABLE_DEBUG_ENDPOINTS=false
      - ENABLE_PROFILING=false
      - AUTO_MIGRATE=false
      - SEED_DATA=false
      - JWT_ACCESS_TOKEN_TTL=5m
      - JWT_REFRESH_TOKEN_TTL=7d
      - SESSION_COOKIE_SECURE=true
      - SESSION_MAX_AGE=24h
      - RATE_LIMIT_REQUESTS_PER_MINUTE=1000
      - RATE_LIMIT_BURST_SIZE=50
      - TLS_ENABLED=true
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    healthcheck:
      test: ["CMD", "curl", "-f", "https://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Production AI search
  ai-search:
    build:
      target: production
    environment:
      - ENVIRONMENT=production
      - LOG_LEVEL=info
      - ENABLE_DEBUG_ENDPOINTS=false
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '2.0'
          memory: 1G
        reservations:
          cpus: '1.0'
          memory: 512M

  # Production producer
  producer:
    build:
      target: production
    environment:
      - ENVIRONMENT=production
      - LOG_LEVEL=info
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M

  # Production consumer
  consumer:
    build:
      target: production
    environment:
      - ENVIRONMENT=production
      - LOG_LEVEL=info
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M

  # Production streams
  streams:
    build:
      target: production
    environment:
      - ENVIRONMENT=production
      - LOG_LEVEL=info
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M

  # Production database with optimized settings
  postgres:
    environment:
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8 --locale=C
    command: >
      postgres
      -c max_connections=200
      -c shared_buffers=256MB
      -c effective_cache_size=1GB
      -c maintenance_work_mem=64MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100
      -c random_page_cost=1.1
      -c effective_io_concurrency=200
      -c work_mem=4MB
      -c min_wal_size=1GB
      -c max_wal_size=4GB
      -c max_worker_processes=8
      -c max_parallel_workers_per_gather=4
      -c max_parallel_workers=8
      -c max_parallel_maintenance_workers=4
      -c log_min_messages=warning
      -c log_checkpoints=on
      -c log_connections=on
      -c log_disconnections=on
      -c log_lock_waits=on
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G

  # Production Redis with optimized settings
  redis:
    command: >
      redis-server
      --appendonly yes
      --maxmemory 1gb
      --maxmemory-policy allkeys-lru
      --tcp-keepalive 300
      --timeout 0
      --tcp-backlog 511
      --save 900 1
      --save 300 10
      --save 60 10000
      --stop-writes-on-bgsave-error yes
      --rdbcompression yes
      --rdbchecksum yes
      --loglevel notice
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1.5G
        reservations:
          cpus: '0.5'
          memory: 1G

  # Production Prometheus with longer retention
  prometheus:
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--storage.tsdb.retention.time=90d'
      - '--storage.tsdb.retention.size=50GB'
      - '--web.enable-admin-api=false'
      - '--log.level=info'
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G

  # Production Grafana
  grafana:
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_USERS_ALLOW_ORG_CREATE=false
      - GF_LOG_LEVEL=info
      - GF_ANALYTICS_REPORTING_ENABLED=false
      - GF_ANALYTICS_CHECK_FOR_UPDATES=false
      - GF_SECURITY_DISABLE_GRAVATAR=true
      - GF_SNAPSHOTS_EXTERNAL_ENABLED=false
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  # Production Jaeger with persistent storage
  jaeger:
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - SPAN_STORAGE_TYPE=elasticsearch
      - ES_SERVER_URLS=http://elasticsearch:9200
      - LOG_LEVEL=info
    depends_on:
      - elasticsearch

  # Elasticsearch for Jaeger storage
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0
    container_name: go-coffee-elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - go-coffee-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Production Nginx with SSL
  nginx:
    volumes:
      - ./deployments/nginx/nginx.prod.conf:/etc/nginx/nginx.conf
      - ./deployments/nginx/ssl:/etc/nginx/ssl:ro
      - ./deployments/nginx/logs:/var/log/nginx
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M

  # Production AlertManager
  alertmanager:
    environment:
      - ALERTMANAGER_WEBHOOK_URL=${ALERT_WEBHOOK_URL}
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
        reservations:
          cpus: '0.1'
          memory: 64M

  # Production exporters
  node-exporter:
    deploy:
      mode: global
      resources:
        limits:
          cpus: '0.1'
          memory: 64M
        reservations:
          cpus: '0.05'
          memory: 32M

  redis-exporter:
    deploy:
      resources:
        limits:
          cpus: '0.1'
          memory: 64M
        reservations:
          cpus: '0.05'
          memory: 32M

  postgres-exporter:
    deploy:
      resources:
        limits:
          cpus: '0.1'
          memory: 64M
        reservations:
          cpus: '0.05'
          memory: 32M

  # Backup service for production
  backup-service:
    image: postgres:15-alpine
    container_name: go-coffee-backup
    environment:
      - PGPASSWORD=${DB_PASSWORD}
      - BACKUP_SCHEDULE=${BACKUP_SCHEDULE:-0 2 * * *}
      - BACKUP_RETENTION_DAYS=${BACKUP_RETENTION_DAYS:-30}
      - S3_BUCKET=${BACKUP_S3_BUCKET}
      - AWS_ACCESS_KEY_ID=${BACKUP_S3_ACCESS_KEY}
      - AWS_SECRET_ACCESS_KEY=${BACKUP_S3_SECRET_KEY}
    volumes:
      - ./scripts/backup.sh:/backup.sh
      - backup_data:/backups
    command: >
      sh -c "
        apk add --no-cache aws-cli &&
        chmod +x /backup.sh &&
        crond -f -l 2
      "
    depends_on:
      - postgres
    networks:
      - go-coffee-network
    profiles:
      - backup

volumes:
  elasticsearch_data:
    driver: local
  backup_data:
    driver: local
